{
	"name": "02 King County Housing",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "Spark1",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2
		},
		"metadata": {
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/58f8824d-32b0-4825-9825-02fa6a801546/resourceGroups/prlangadrg/providers/Microsoft.Synapse/workspaces/synapsedemosws/bigDataPools/Spark1",
				"name": "Spark1",
				"type": "Spark",
				"endpoint": "https://synapsedemosws.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/Spark1",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "2.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28
			}
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"import numpy as np\n",
					"import pandas as pd\n",
					"import seaborn as sns\n",
					"import matplotlib.pyplot as plt\n",
					"from pyspark.ml.stat import Correlation\n",
					"from pyspark.ml.feature import VectorAssembler\n",
					"from pyspark.ml.regression import LinearRegression\n",
					"from pyspark.ml.feature import RFormula\n",
					"from pyspark.ml import Pipeline\n",
					"from pyspark.ml import PipelineModel\n",
					"from pyspark.mllib.evaluation import RegressionMetrics\n",
					"from pyspark.ml.evaluation import RegressionEvaluator"
				],
				"execution_count": 3
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Read File\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"%%pyspark\n",
					"df = spark.read.load('abfss://rawdata@synapsedemos.dfs.core.windows.net/King County Housing/kc_house_data.csv', format='csv'\n",
					", header=True\n",
					",inferSchema=True\n",
					")\n",
					"#df.show(10)"
				],
				"attachments": null,
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"source": [
					"df.printSchema()\n",
					"df_coldropped = df.drop(\"id\",\"date\")\n",
					"df_coldropped.printSchema()\n",
					"#df_coldropped.columns"
				],
				"execution_count": 5
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Column and Description\n",
					"    Id: Unique Id for each field\n",
					"    Date: Date of the home sale\n",
					"    Price: Price of each home sale\n",
					"    Bedroom: Number of bedrooms\n",
					"    Bathroom: Number of bathrooms, where 0.5 accounts for a room with a toilet but no shower\n",
					"    Sqft_living: Sqaure footage of the apartments interior living space\n",
					"    Sqft_lot: Square footage of the land space\n",
					"    floors: Number of floors\n",
					"    waterfront: A dummy variable for whether the apartment was overlooking the waterfront\n",
					"    view: An index from 0 to 4 of how good the view of the property was\n",
					"    condition: An index from 1 to 5 on the condition of the apartment\n",
					"    grade: An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an avergage level of construction and designm,  and 11-13 have a high quality construction and design\n",
					"    sqft_above: Square footage of the interior housing space that is above  ground level\n",
					"    sqft_basement: Square footage of the interior housing space that is below  ground level\n",
					"    yr_built: The year house was initially built\n",
					"    yr_renovated: The year of the house's last renovation\n",
					"    zipcode: The area code where house is located\n",
					"    lat: Lattitude\n",
					"    long: Longitude\n",
					"    sqft_living15: Square footage of interior housing living space for the nearest 15 neighbors\n",
					"    sqft_lot15: Square footage of the land lots of the nearest 15 neighbors\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Exploratory Data Analysis\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"df_coldropped.describe()\n",
					"df_coldropped.createOrReplaceTempView(\"dfKingCounty\")"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"source": [
					"df_pandas = df_coldropped.toPandas()\n",
					"print(df_pandas.isnull().any())\n",
					"print(df_pandas.dtypes)\n",
					"print(df_pandas.describe(include='all'))"
				],
				"execution_count": 7
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Feature Engineering\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"df_pandas['price'] = pd.to_numeric(df_pandas['price'])\n",
					"df_pandas.head(5)"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"source": [
					"df_pandas.describe()"
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"source": [
					"pd.set_option('precision',2)\n",
					"print(df_pandas.describe())"
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"source": [
					"df_pandas.hist(bins=50,figsize=(20,15))\n",
					"plt.show()"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"source": [
					"correlation = df_pandas.corr(method='pearson')\n",
					"correlation\n",
					"columns = correlation.nlargest(10, 'price').index\n",
					"columns"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"source": [
					"correlation_map = np.corrcoef(df_pandas[columns].values.T)\n",
					"\n",
					"plt.figure(figsize=(8,8))\n",
					"sns.set(font_scale=0.8)\n",
					"heatmap = (sns.heatmap(correlation_map,cbar=True,annot=True, square = True, fmt='.2f'\n",
					"            , yticklabels= columns.values, xticklabels = columns.values))\n",
					"plt.show()\n",
					""
				],
				"execution_count": 14
			},
			{
				"cell_type": "code",
				"source": [
					"corr_matrix = df_pandas.corr()\n",
					"#plt.figure(figsize=(10,10))\n",
					"s=corr_matrix['price'].sort_values(ascending=False)\n",
					"print(s)\n",
					"#s.plot.bar()"
				],
				"execution_count": 15
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Feature Extraction\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"diagram": {
						"activateDiagramType": 1,
						"chartConfig": {
							"category": "bar",
							"keys": [
								"bathrooms"
							],
							"values": [
								"bedrooms"
							],
							"yLabel": "bedrooms",
							"xLabel": "bathrooms",
							"aggregation": "SUM",
							"aggByBackend": false
						},
						"aggData": {
							"bedrooms": {
								"0": 0,
								"1": 521,
								"2": 320,
								"3": 133,
								"4": 17,
								"5": 10,
								"0.75": 8,
								"1.25": 3,
								"1.5": 184,
								"1.75": 515,
								"2.25": 368,
								"2.5": 853,
								"2.75": 202,
								"3.25": 70,
								"3.5": 117,
								"3.75": 4,
								"4.25": 17,
								"4.5": 7,
								"4.75": 4
							}
						},
						"isSummary": false,
						"previewData": {
							"filter": null
						},
						"isSql": false
					}
				},
				"source": [
					"#featureCols = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'sqft_living15', 'sqft_lot15']\n",
					"\n",
					"featureCols = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'waterfront', 'view', 'grade', 'sqft_above', 'sqft_basement',  'sqft_living15']\n",
					"\n",
					"df_mlInput = df_coldropped.select(featureCols)\n",
					"#print(df_mlInput.type)\n",
					"display(df_mlInput)"
				],
				"execution_count": 25
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Don't run this part of code\n",
					"Use Vector Assembler to put features into a feature vector column\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"assembler = VectorAssembler(inputCols = featureCols, outputCol = \"features\")"
				],
				"execution_count": 18
			},
			{
				"cell_type": "code",
				"metadata": {
					"diagram": {
						"activateDiagramType": 1,
						"chartConfig": {
							"category": "bar",
							"keys": [
								"bedrooms"
							],
							"values": [
								"price"
							],
							"yLabel": "price",
							"xLabel": "bedrooms",
							"aggregation": "SUM",
							"aggByBackend": false
						},
						"aggData": {
							"price": {
								"0": 1095000,
								"1": 1700900,
								"2": 45070710,
								"3": 223073427,
								"4": 188881487,
								"5": 51901810,
								"6": 7441500,
								"7": 1950000
							}
						},
						"isSummary": false,
						"previewData": {
							"filter": null
						},
						"isSql": false
					}
				},
				"source": [
					"assembled_df = assembler.transform(df_coldropped)\n",
					"#assembled_df.show(10, truncate=False)\n",
					"display(assembled_df)"
				],
				"execution_count": 20
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Build a ML Model with Spark ML\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Setting random seed for notebook reproducability\n",
					"rnd_seed=23\n",
					"np.random.seed=rnd_seed\n",
					"np.random.set_state = rnd_seed\n",
					"\n",
					"# Split the data into train and test sets\n",
					"train_data_df, test_data_df = df_mlInput.randomSplit([0.7,0.3],seed=rnd_seed)\n",
					"train_data_df.columns"
				],
				"execution_count": 26
			},
			{
				"cell_type": "code",
				"source": [
					"# Initialize 'lr'\n",
					"#lr = (LinearRegression(featuresCol = 'features', labelCol = \"price\", predictionCol = \"predPrice\", \n",
					"#maxIter=10, regParam=0.3, elasticNetParam=0.8, standardization=False))\n",
					"\n",
					"## Create a new LR object for the model\n",
					"linReg = LinearRegression(maxIter=10, regParam=0.3, labelCol = 'price')\n",
					"\n",
					"## The formula for the model\n",
					"classFormula = RFormula(formula=\"price ~ bedrooms + bathrooms + sqft_living + waterfront + view + grade + sqft_above + sqft_basement + sqft_living15\")\n",
					"\n",
					"## Undertake training and create an LR model\n",
					"lrModel = Pipeline(stages=[classFormula, linReg]).fit(train_data_df)"
				],
				"execution_count": 27
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Evaluating the Model\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Coefficients for the model\n",
					"lrModel.coefficients"
				],
				"execution_count": 29
			},
			{
				"cell_type": "code",
				"source": [
					"# intercept for the model\n",
					"lrModel.intercept"
				],
				"execution_count": 34
			},
			{
				"cell_type": "code",
				"source": [
					"coeff_df = pd.DataFrame ({\"Feature\":[\"Intercept\"] + featureCols, \n",
					"\"Co-efficients\": np.insert(linearModel.coefficients.toArray(),0,linearModel.intercept)})\n",
					"coeff_df = coeff_df[[\"Feature\",\"Co-efficients\"]]"
				],
				"execution_count": 35
			},
			{
				"cell_type": "code",
				"source": [
					"coeff_df"
				],
				"execution_count": 37
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Generate Predictions\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"#predictions = lrModel.transform(test_data)\n",
					"predictions = lrModel.transform(test_data_df)\n",
					"predictionAndLabels = predictions.select(\"label\",\"predPrice\").rdd\n",
					""
				],
				"execution_count": 30
			},
			{
				"cell_type": "code",
				"source": [
					"# Extract the predictions and the \"known\" correct labels\n",
					"predandlabels = predictions.select(\"predPrice\",\"Price\")\n",
					"predandlabels.show()"
				],
				"execution_count": 39
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Inspecting the Model\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"The RMSE measures how much error there is between two datasets comparing a predicted value and an observed or known value. The smaller an RMSE value, the closer predicted and observed values are.\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# get the RMSE , MAE\n",
					"print(\"RMSE : {0}\".format(lrModel.summary.rootMeanSquaredError))\n",
					"print(\"MAE:{0}\".format(lrModel.summary.meanAbsoluteError))"
				],
				"execution_count": 40
			},
			{
				"cell_type": "markdown",
				"source": [
					"The R2 (\"R squared\") or the coefficient of determination is a measure that shows how close the data are to the fitted regression line. This score will always be between 0 and a 100% (or 0 to 1 in this case), where 0% indicates that the model explains none of the variability of the response data around its mean, and 100% indicates the opposite: it explains all the variability. That means that, in general, the higher the R-squared, the better the model fits our data.\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Get the r-squared\n",
					"print(\"R2: {0}\".format(lrModel.summary.r2))"
				],
				"execution_count": 42
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Using Regression Evaluator from pyspark.ml package\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"evaluator = RegressionEvaluator(predictionCol = \"predPrice\", labelCol = \"Price\", metricName='rmse')\n",
					"print(\"RMSE:{0}\".format(evaluator.evaluate(predictionAndLabels)))\n",
					"evaluator = RegressionEvaluator(predictionCol = \"predPrice\", labelCol = \"Price\", metricName='mae')\n",
					"print(\"MAE:{0}\".format(evaluator.evaluate(predictionAndLabels)))\n",
					"evaluator = RegressionEvaluator(predictionCol = \"predPrice\", labelCol = \"Price\", metricName='r2')\n",
					"print(\"R2:{0}\".format(evaluator.evaluate(predictionAndLabels)))"
				],
				"execution_count": 43
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Using the RegressionMetrics from pyspark.mllib package\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"metrics = RegressionMetrics(predandlabels.rdd)"
				],
				"execution_count": 46
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Export Model in ONNX Format\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from onnxmltools import convert_sparkml\n",
					"from onnxmltools.convert.sparkml.utils import buildInitialTypesSimple"
				],
				"execution_count": 50
			},
			{
				"cell_type": "code",
				"source": [
					"#drop all columns except selected columns: ['bedrooms', 'bathrooms', 'sqft_living', 'waterfront', 'view', 'grade', 'sqft_above', 'sqft_basement', 'sqft_living15']\n",
					"#initial_types = buildInitialTypesSimple(test_data.drop('price','features', 'sqft_lot', 'floors', 'condition', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_lot15'))\n",
					"initial_types = buildInitialTypesSimple(train_data.drop(\"price\",\"features\", 'sqft_lot', 'floors', 'condition', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_lot15'))"
				],
				"execution_count": 78
			},
			{
				"cell_type": "code",
				"source": [
					"onnx_model = convert_sparkml(linearModel, \"Pyspark model\",initial_types)"
				],
				"execution_count": 86
			},
			{
				"cell_type": "code",
				"source": [
					"with open(os.path.join(\"/tmp/\", \"model.onnx\"), \"wb\") as f:\n",
					"    f.write(onnx_model.SerializeToString())"
				],
				"execution_count": 64
			}
		]
	}
}