{
	"name": "02 Predict Retail Sales with HB",
	"properties": {
		"folder": {
			"name": "Test notebooks"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "analyticspool",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2
		},
		"metadata": {
			"kernelspec": {
				"name": "python_defaultSpec_1599520475833",
				"display_name": "Python 3.6.7 64-bit"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/7e416de3-c506-4776-8270-83fd73c6cc37/resourceGroups/demosynapserg/providers/Microsoft.Synapse/workspaces/wsazuresynapseanalytics/bigDataPools/analyticspool",
				"name": "analyticspool",
				"type": "Spark",
				"endpoint": "https://wsazuresynapseanalytics.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/analyticspool",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "2.4",
				"nodeCount": 3,
				"cores": 8,
				"memory": 56
			}
		},
		"cells": [
			{
				"cell_type": "markdown",
				"source": [
					"## Import scikit-learn's RandomForestClassifier, ONNX, and Hummingbird\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from datetime import datetime\n",
					"from timeit import default_timer as timer\n",
					"import time\n",
					"\n",
					"import numpy as np\n",
					"import pandas as pd\n",
					"from sklearn.ensemble import RandomForestClassifier\n",
					"from sklearn.model_selection import train_test_split\n",
					"\n",
					"import onnxruntime as ort\n",
					"from onnxmltools.convert import convert_sklearn\n",
					"from onnxconverter_common.data_types import FloatTensorType\n",
					"\n",
					"import hummingbird.ml"
				],
				"attachments": null,
				"execution_count": 4
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Read in the data and convert to Pandas \n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"diagram": {
						"activateDiagramType": 1,
						"chartConfig": {
							"category": "bar",
							"keys": [
								"_rid"
							],
							"values": [
								"_ts"
							],
							"yLabel": "_ts",
							"xLabel": "_rid",
							"aggregation": "SUM",
							"aggByBackend": false
						},
						"aggData": "{\"_ts\":{\"sY0TAIh7N8gBAAAAAAAABA==\":1598476494,\"sY0TAIh7N8gCAAAAAAAABA==\":1598476494,\"sY0TAIh7N8gDAAAAAAAABA==\":1598476494}}",
						"isSummary": false,
						"previewData": {
							"filter": null
						},
						"isSql": false
					}
				},
				"source": [
					"# Load and join data\n",
					"df_StoreDemographics = spark.read\\\n",
					"                        .format(\"cosmos.olap\")\\\n",
					"                        .option(\"spark.synapse.linkedService\", \"RetailSalesDemoDB\")\\\n",
					"                        .option(\"spark.cosmos.container\", \"StoreDemoGraphics\")\\\n",
					"                        .load()\\\n",
					"                        .toPandas()\n",
					"\n",
					"df_RetailSales = spark.read\\\n",
					"                        .format(\"cosmos.olap\")\\\n",
					"                        .option(\"spark.synapse.linkedService\", \"RetailSalesDemoDB\")\\\n",
					"                        .option(\"spark.cosmos.container\", \"RetailSales\")\\\n",
					"                        .load()\\\n",
					"                        .toPandas()\n",
					"\n",
					"df_Products = spark.read\\\n",
					"                    .format(\"cosmos.olap\")\\\n",
					"                    .option(\"spark.synapse.linkedService\", \"RetailSalesDemoDB\")\\\n",
					"                    .option(\"spark.cosmos.container\", \"Products\")\\\n",
					"                    .load()\\\n",
					"                    .toPandas()\n",
					"\n",
					"display(df_Products.head(10))\n",
					"\n",
					"df = df_RetailSales.merge(df_Products, on=['productCode'], how='left').merge(df_StoreDemographics, on=['storeId'], how = 'left')\n",
					"df.head(5)"
				],
				"attachments": null,
				"execution_count": 46
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Define some featurizers: dictionary encoder and date featurizer\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"cellLanguage": "python",
					"tags": [
						"parameters"
					]
				},
				"source": [
					"\n",
					"\n",
					"def dictionary_encode(df, column, dictionary):\n",
					"\n",
					"    def add_into_dict(value, dictionary):\n",
					"        count = 0\n",
					"        if len(dictionary) > 0:\n",
					"            count = max(dictionary.values())\n",
					"        count += 1\n",
					"        dictionary[value] = count\n",
					"        return count\n",
					"\n",
					"    df[column] = pd.DataFrame(df[column].values)[0].apply(lambda x: dictionary[x] if x in dictionary else add_into_dict(x, dictionary))\n",
					"\n",
					"def date_featurize(df,column):\n",
					"    df[column] = pd.DataFrame(df[column].values)[0].apply(lambda x: (int(datetime.strptime(x, '%m/%d/%Y').strftime('%m%d%Y'))))"
				],
				"attachments": null,
				"execution_count": 47
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Featurize the data\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"dictionary = {}\n",
					"\n",
					"dictionary_encode(df,'productCode', dictionary)\n",
					"date_featurize(df,'weekStarting')\n",
					"df.head()"
				],
				"attachments": null,
				"execution_count": 48
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Drop unecessary columns\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"df = df.drop(columns=['logQuantity', '_rid_x', '_rid_y', 'id','_rid','_ts','_ts_x','_ts_y','_etag','_etag_x','_etag_y','id_x','id_y'])\n",
					"df.head()"
				],
				"attachments": null,
				"execution_count": 50
			},
			{
				"cell_type": "code",
				"source": [
					"df=df.apply(pd.to_numeric, errors=\"ignore\")"
				],
				"execution_count": 54
			},
			{
				"cell_type": "code",
				"source": [
					"df.dtypes"
				],
				"execution_count": 55
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Define the target column (i.e., what we want to predict)\n",
					"\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"target = np.array(df['quantity'])"
				],
				"attachments": null,
				"execution_count": 56
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Define the features\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"features = df.drop('quantity', axis = 1)\n",
					"\n",
					"# Convert to numpy array\n",
					"features = np.array(features).astype(np.float32)"
				],
				"attachments": null,
				"execution_count": 57
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Generate a train-test split of the dataset\n",
					"\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"train_features, test_features, train_labels, _ = train_test_split(features, target, test_size = 0.20)"
				],
				"attachments": null,
				"execution_count": 58
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Almost there! Train a Regression model on the data\n",
					"\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"model = RandomForestClassifier(n_estimators=10, max_depth=10)\n",
					"model.fit(train_features, train_labels)"
				],
				"attachments": null,
				"execution_count": 59
			},
			{
				"cell_type": "markdown",
				"source": [
					"# First: ONNX (Traditional) using ONNXMLTOOLS\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Convert the trained model into ONNX (Traditional) using ONNXMLTOOLS"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"%%capture \n",
					"initial_types = [(\"input\", FloatTensorType([test_features.shape[0], test_features.shape[1]]))] # Define the inputs for the ONNX\n",
					"onnx_ml_model = convert_sklearn(\n",
					"    model, initial_types=initial_types, target_opset=11\n",
					")"
				],
				"attachments": null,
				"execution_count": 60
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Setup the Inference Session for the ONNX (Traditional) model\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"sess = ort.InferenceSession(onnx_ml_model.SerializeToString())\n",
					"input_name = sess.get_inputs()[0].name\n",
					"target_name = sess.get_outputs()[0].name"
				],
				"attachments": null,
				"execution_count": 61
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Time the ONNX (Traditional) model\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"tags": []
				},
				"source": [
					"%%timeit\n",
					"sess.run([target_name], {input_name: test_features})"
				],
				"attachments": null,
				"execution_count": 62
			},
			{
				"cell_type": "markdown",
				"source": [
					"# Now: ONNX (DNN) using Hummingbird"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Convert the trained model into ONNX (DNN) using Humingbird\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"hb_model = hummingbird.ml.convert(model, \"onnx\", test_features)"
				],
				"attachments": null,
				"execution_count": 63
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Time the ONNX (DNN) model\n",
					"#### Note that this function call also setups the Inference Session\n",
					""
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"tags": []
				},
				"source": [
					"%%timeit\n",
					"# Run predictions using the hb model\n",
					"hb_model.predict(test_features)"
				],
				"attachments": null,
				"execution_count": 64
			},
			{
				"cell_type": "code",
				"source": [],
				"execution_count": null
			}
		]
	}
}